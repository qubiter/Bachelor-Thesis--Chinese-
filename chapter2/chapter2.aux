\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{unsrt}
\FN@pp@footnotehinttrue 
\@writefile{toc}{\contentsline {chapter}{\numberline {2}机器学习与深度学习简介}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter_machinelearning}{{2}{5}{机器学习与深度学习简介}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}机器学习}{5}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}机器学习简介}{5}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}定义与引例}{5}{subsubsection.2.1.1.1}}
\newlabel{eqn:random}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{1}}{5}{定义与引例}{equation.2.1.1}{}}
\citation{standford_machine_learning_cs229}
\citation{standford_machine_learning_cs229}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{1}}{\ignorespaces 拟合的原数据点，真实的Sine函数\relax }}{6}{figure.caption.9}}
\newlabel{fig:fitting}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{1}}{6}{拟合的原数据点，真实的Sine函数\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{2}}{\ignorespaces 多项式“拟合”：对真实情况进行预测、推断\relax }}{6}{figure.caption.10}}
\newlabel{fig:polyfitting}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{2}}{6}{多项式“拟合”：对真实情况进行预测、推断\relax }{figure.caption.10}{}}
\citation{mitchell1997machine}
\citation{mitchell1997machine}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}机器学习的分类}{8}{subsubsection.2.1.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}监督学习}{8}{subsection.2.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}优化方法之梯度下降法}{9}{subsubsection.2.1.2.1}}
\newlabel{eqn:costfunction}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{6}}{9}{优化方法之梯度下降法}{equation.2.1.6}{}}
\citation{standford_machine_learning_cs229}
\citation{standford_machine_learning_cs229}
\citation{wikipedia_BGFS_algorithm}
\citation{wikipedia_BGFS_algorithm}
\citation{wikipedia_perceptron}
\citation{wikipedia_perceptron}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}Sigmoid分类实现方法}{10}{subsubsection.2.1.2.2}}
\citation{standford_machine_learning_cs229}
\citation{standford_machine_learning_cs229}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{3}}{\ignorespaces Sigmoid函数的形状\relax }}{11}{figure.caption.11}}
\newlabel{fig:sigmoid}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{3}}{11}{Sigmoid函数的形状\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{4}}{\ignorespaces Cost函数与h的关系(y=1)\relax }}{12}{figure.caption.12}}
\newlabel{fig:sigmoidcost1}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{4}}{12}{Cost函数与h的关系(y=1)\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{5}}{\ignorespaces Cost函数与h的关系(y=0)\relax }}{12}{figure.caption.13}}
\newlabel{fig:sigmoidcost0}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{5}}{12}{Cost函数与h的关系(y=0)\relax }{figure.caption.13}{}}
\citation{standford_machine_learning_cs229}
\citation{standford_machine_learning_cs229}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3}神经网络}{13}{subsubsection.2.1.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{6}}{\ignorespaces 二层神经网络结构示意\relax }}{14}{figure.caption.14}}
\newlabel{fig:neuralnetwork}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{6}}{14}{二层神经网络结构示意\relax }{figure.caption.14}{}}
\citation{standford_machine_learning_cs229}
\citation{standford_machine_learning_cs229}
\citation{deep_learning_ufldl}
\citation{deep_learning_ufldl}
\newlabel{enu: backprop}{{2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3}{16}{神经网络}{equation.2.1.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}4}Bayes公式与机器学习}{17}{subsubsection.2.1.2.4}}
\citation{standford_machine_learning_cs229}
\citation{standford_machine_learning_cs229}
\@writefile{toc}{\contentsline {subsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3}非监督学习}{19}{subsection.2.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}k-means聚类方法}{19}{subsubsection.2.1.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{7}}{\ignorespaces k-means聚类分析过程：“×”形代表聚类中心。\relax }}{20}{figure.caption.15}}
\newlabel{fig:kmeans}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{7}}{20}{k-means聚类分析过程：“×”形代表聚类中心。\relax }{figure.caption.15}{}}
\citation{Duda2001Pattern}
\citation{Duda2001Pattern}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}Gaussian混合聚类模型}{21}{subsubsection.2.1.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{8}}{\ignorespaces k-means聚类之难：交叠处(x=2.5)到底属于哪一个聚类？\relax }}{22}{figure.caption.16}}
\newlabel{fig:kmeansproblem}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{8}}{22}{k-means聚类之难：交叠处(x=2.5)到底属于哪一个聚类？\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3}自编码神经网络}{23}{subsubsection.2.1.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{9}}{\ignorespaces 主元分析对于Gaussian分布数据的影响\relax }}{24}{figure.caption.17}}
\newlabel{fig:pca}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{9}}{24}{主元分析对于Gaussian分布数据的影响\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{10}}{\ignorespaces 自编码神经网络结构示意\relax }}{24}{figure.caption.18}}
\newlabel{fig:pca}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{10}}{24}{自编码神经网络结构示意\relax }{figure.caption.18}{}}
\citation{Duda2001Pattern}
\citation{Duda2001Pattern}
\citation{bellman1957dynamic}
\citation{bellman1957dynamic}
\citation{bengio2009learning}
\citation{bengio2009learning}
\citation{bengio2009learning}
\citation{bengio2009learning}
\@writefile{toc}{\contentsline {section}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}深度学习}{25}{section.2.2}}
\citation{JMLR:v15:srivastava14a}
\citation{JMLR:v15:srivastava14a}
\citation{deep_learning_ufldl}
\citation{deep_learning_ufldl}
\citation{hinton2006fast}
\citation{hinton2006fast}
\citation{lee2009convolutional}
\citation{lee2009convolutional}
\@writefile{toc}{\contentsline {subsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}卷积神经网络}{26}{subsection.2.2.1}}
\citation{Hyv2009Natural}
\citation{Hyv2009Natural}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}部分联通网络的必要性}{27}{subsubsection.2.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{11}}{\ignorespaces 部分连接网络示意\relax }}{27}{figure.caption.19}}
\newlabel{fig:localnetwork}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{11}}{27}{部分连接网络示意\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}图像特征的全局性，参数共享与卷积}{27}{subsubsection.2.2.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{12}}{\ignorespaces 二维离散有限卷积示意\relax }}{28}{figure.caption.20}}
\newlabel{fig:conv}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{12}}{28}{二维离散有限卷积示意\relax }{figure.caption.20}{}}
\citation{deep_learning_ufldl}
\citation{deep_learning_ufldl}
\newlabel{eqn:conv}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{31}}{29}{图像特征的全局性，参数共享与卷积}{equation.2.2.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{13}}{\ignorespaces 通过卷积进行输入层到中间层的连接\relax }}{29}{figure.caption.21}}
\newlabel{fig:convker}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{13}}{29}{通过卷积进行输入层到中间层的连接\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}3}特征归并：池化}{30}{subsubsection.2.2.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{14}}{\ignorespaces 典型的卷积神经网络结构(LeNet)\relax }}{30}{figure.caption.22}}
\newlabel{fig:lenet}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{14}}{30}{典型的卷积神经网络结构(LeNet)\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}深度信念网络}{30}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}1}受限Boltzmann机模型}{31}{subsubsection.2.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{15}}{\ignorespaces 受限Boltzmann机示意\relax }}{31}{figure.caption.23}}
\newlabel{fig:rbm}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{15}}{31}{受限Boltzmann机示意\relax }{figure.caption.23}{}}
\citation{hinton2006fast}
\citation{hinton2006fast}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2\tmspace  +\thinmuskip {.1667em}.\tmspace  +\thinmuskip {.1667em}2}DBN的结构}{32}{subsubsection.2.2.2.2}}
\citation{lee2009convolutional}
\citation{lee2009convolutional}
\@writefile{lof}{\contentsline {figure}{\numberline {{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{16}}{\ignorespaces DBN架构示意\relax }}{33}{figure.caption.24}}
\newlabel{fig:dbn}{{{2}\kern .07em\rule  [.5ex]{.4em}{.15ex}\kern .07em{16}}{33}{DBN架构示意\relax }{figure.caption.24}{}}
\FN@pp@footnotehinttrue 
\@setckpt{chapter2/chapter2}{
\setcounter{page}{34}
\setcounter{equation}{39}
\setcounter{enumi}{4}
\setcounter{enumii}{2}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{2}
\setcounter{subsection}{2}
\setcounter{subsubsection}{2}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{16}
\setcounter{table}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{float@type}{16}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{parentequation}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{AM@survey}{0}
\setcounter{algorithm}{0}
\setcounter{Item}{27}
\setcounter{Hfootnote}{0}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{20}
\setcounter{NAT@ctr}{0}
\setcounter{su@anzahl}{0}
\setcounter{pp@next@reset}{1}
\setcounter{@fnserial}{0}
\setcounter{definition}{0}
\setcounter{theorem}{0}
\setcounter{hypothesis}{0}
\setcounter{axiom}{0}
\setcounter{postulate}{0}
\setcounter{principle}{0}
\setcounter{problem}{0}
\setcounter{exercise}{0}
\setcounter{example}{0}
\setcounter{remark}{0}
\setcounter{arabicenumi}{0}
\setcounter{arabicenumii}{0}
\setcounter{arabicenumiii}{0}
\setcounter{romanenumi}{0}
\setcounter{romanenumii}{0}
\setcounter{alphaenumi}{0}
\setcounter{alphaenumii}{0}
\setcounter{caseenumi}{0}
\setcounter{caseenumii}{0}
\setcounter{stepenumi}{0}
\setcounter{stepenumii}{0}
\setcounter{lstnumber}{1}
\setcounter{section@level}{0}
\setcounter{lstlisting}{0}
}
